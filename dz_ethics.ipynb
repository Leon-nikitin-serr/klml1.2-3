{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8134d54-1f26-4935-bdbb-c2c8db804f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a33c12-8b06-4b65-994b-d1d3af11f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same results each time\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Load the training data\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "comments = data[\"comment_text\"]\n",
    "target = (data[\"target\"]>0.7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999f7a68-1b21-4b57-b6ba-9d87b834b54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239607</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>Yet call out all Muslims for the acts of a few...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26670</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239612</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>This bitch is nuts. Who would read a book by a...</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26674</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240311</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>You're an idiot.</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32846</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240329</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>Who cares!? Stark trek and Star Wars fans are ...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32846</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    target                                       comment_text  \\\n",
       "0   59856  0.893617               haha you guys are a bunch of losers.   \n",
       "1  239607  0.912500  Yet call out all Muslims for the acts of a few...   \n",
       "2  239612  0.830769  This bitch is nuts. Who would read a book by a...   \n",
       "3  240311  0.968750                                   You're an idiot.   \n",
       "4  240329  0.900000  Who cares!? Stark trek and Star Wars fans are ...   \n",
       "\n",
       "   severe_toxicity   obscene  identity_attack    insult  threat  asian  \\\n",
       "0         0.021277  0.000000         0.021277  0.872340  0.0000    0.0   \n",
       "1         0.050000  0.237500         0.612500  0.887500  0.1125    0.0   \n",
       "2         0.107692  0.661538         0.338462  0.830769  0.0000    0.0   \n",
       "3         0.031250  0.062500         0.000000  0.968750  0.0000    NaN   \n",
       "4         0.100000  0.200000         0.000000  0.900000  0.0000    NaN   \n",
       "\n",
       "   atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "0      0.0  ...        2006  rejected      0    0    0      1         0   \n",
       "1      0.0  ...       26670  approved      0    0    0      1         0   \n",
       "2      0.0  ...       26674  rejected      0    0    0      0         0   \n",
       "3      NaN  ...       32846  rejected      0    0    0      0         0   \n",
       "4      NaN  ...       32846  rejected      0    0    0      0         0   \n",
       "\n",
       "   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "0         0.000000                         4                        47  \n",
       "1         0.000000                         4                        80  \n",
       "2         0.061538                         4                        65  \n",
       "3         0.000000                         0                        32  \n",
       "4         0.300000                         0                        10  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e79ee5-4b6d-4fa3-bb3f-cfa9283aa699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 90902 entries, 0 to 90901\n",
      "Series name: comment_text\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "90902 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 710.3+ KB\n"
     ]
    }
   ],
   "source": [
    "comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f7aa87-2f81-4113-84bb-64a76818bd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    45451\n",
       "0    45451\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f93092-7fc1-4431-8e20-8c3defaffe6d",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7549bc3c-8258-491c-9f61-b236edcfad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    comments, target,           # данные\n",
    "    test_size=0.3,  # 30% — тестовая выборка, 70% — обучающая\n",
    "    random_state=42 # фиксируем случайность для повторяемости\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63684f4d-b86e-4a3e-ae9c-67cb4698b7c6",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00555a98-6a12-4ba7-9d46-d2b3407d5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем экземпляр векторизатора\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Обучаем векторизатор на тренировочных данных и трансформируем их в числовой формат\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Трансформируем тестовые данные (без повторного обучения)\n",
    "X_test_vec= vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d253c332-5307-4adc-b095-b523feebd3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерноть датасета X_train_vec (63631, 57878)\n",
      "Размерность датасета y_train (63631,)\n",
      "Размерноть датасета X_train_vec (27271, 57878)\n",
      "Размерность датасета y_train (27271,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Размерноть датасета X_train_vec', X_train_vec.shape)\n",
    "print(f'Размерность датасета y_train', y_train.shape)\n",
    "print(f'Размерноть датасета X_train_vec', X_test_vec.shape)\n",
    "print(f'Размерность датасета y_train', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d80a4-670e-43c8-af1a-f885455a988a",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83006986-e902-410d-ba5f-d77280283164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели логистической регрессии: 0.9276\n"
     ]
    }
   ],
   "source": [
    "# Создаем и обучаем модель логистической регрессии\n",
    "model = LogisticRegression(max_iter=2000, random_state=42)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Оцениваем точность модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy модели логистической регрессии: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e60d9db-c08f-4ee7-a9b0-4c60b2cd77bd",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b79728-8d7e-49b5-bd4a-600480853342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_toxicity(comment):\n",
    "    # Векторизуем текст\n",
    "    comment_vec = vectorizer.transform([comment])\n",
    "    \n",
    "    # Получаем вероятность принадлежности к классу 1 (токсичный)\n",
    "    probability = model.predict_proba(comment_vec)[0][1]\n",
    "    \n",
    "    if probability > 0.7:\n",
    "        print(f'Токсичный комментарий: \"{comment}\"')\n",
    "        print(f'Вероятность токсичности: {probability:.4f}')\n",
    "        return probability\n",
    "    else:\n",
    "        print(f'Нетоксичный комментарий: \"{comment}\"')\n",
    "        print(f'Вероятность токсичности: {probability:.4f}')\n",
    "        return probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc109cb9-4ec9-41ed-985d-46daf1295384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токсичный комментарий: \"You are loser\"\n",
      "Вероятность токсичности: 0.9678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9678070844890234"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_toxicity(\"You are loser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d32742-8555-41e3-937a-70e612a0db9b",
   "metadata": {},
   "source": [
    "# Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "458f6a07-e688-407a-9279-81fbdb6a44ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токсичный комментарий: \"Apples are stupid\"\n",
      "Вероятность токсичности: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9991090380382668"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_toxicity(\"Apples are stupid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90e323a-ae62-4876-aff2-d721bf3e1bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нетоксичный комментарий: \"I love apples\"\n",
      "Вероятность токсичности: 0.0587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0586974796290112"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_toxicity(\"I love apples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776524d-fb47-4c9a-887c-0b46126dcb57",
   "metadata": {},
   "source": [
    "# Задание 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d66edf55-08fc-4c96-9e79-7d94230d5234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 самых токсичных слов и их коэффициенты:\n",
      "stupid: 9.2228\n",
      "idiot: 8.7435\n",
      "idiots: 8.4722\n",
      "stupidity: 7.5524\n",
      "idiotic: 6.8429\n",
      "crap: 6.5858\n",
      "dumb: 6.4476\n",
      "pathetic: 6.4226\n",
      "hypocrite: 6.3940\n",
      "moron: 6.3627\n"
     ]
    }
   ],
   "source": [
    "# Получаем все слова из словаря\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "# Получаем коэффициенты из модели\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Сортируем индексы слов по величине коэффициента\n",
    "sorted_indices = np.argsort(coefficients)\n",
    "\n",
    "# Выводим 10 наиболее токсичных слов (с самыми высокими коэффициентами)\n",
    "print(\"Топ-10 самых токсичных слов и их коэффициенты:\")\n",
    "for index in sorted_indices[-10:][::-1]:\n",
    "    word = list(vocab.keys())[list(vocab.values()).index(index)]  # Находим слово по индексу\n",
    "    print(f\"{word}: {coefficients[index]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1397f6-a4ca-4170-ac0b-4ccef68cec9d",
   "metadata": {},
   "source": [
    "# Задание 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b487874d-d18a-4123-8147-cb681ec4668f",
   "metadata": {},
   "source": [
    "Все слова корректно выбраны,ошибок не обнаружил"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0a920-f05f-409e-93d7-05e0ee1f6489",
   "metadata": {},
   "source": [
    "# Задание 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c4c6547-21b6-48fe-af05-ddc1bd804438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нетоксичный комментарий: \"I have a christian friend\"\n",
      "Вероятность токсичности: 0.1884\n",
      "Нетоксичный комментарий: \"I have a muslim friend\"\n",
      "Вероятность токсичности: 0.5152\n",
      "Нетоксичный комментарий: \"I have a white friend\"\n",
      "Вероятность токсичности: 0.4054\n",
      "Нетоксичный комментарий: \"I have a black friend\"\n",
      "Вероятность токсичности: 0.5955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5954532299859536"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_toxicity(\"I have a christian friend\")\n",
    "predict_toxicity(\"I have a muslim friend\")\n",
    "predict_toxicity(\"I have a white friend\")\n",
    "predict_toxicity(\"I have a black friend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7736e5-ff85-498f-ba59-d0d0b5c56031",
   "metadata": {},
   "source": [
    "Модель этична"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf1d040-b8d3-42ad-928b-c4e935d62d3a",
   "metadata": {},
   "source": [
    "# Задание 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ddf029-c925-4763-a936-3d533720295c",
   "metadata": {},
   "source": [
    "Предвзятость может привести к тому, что даже нейтральное употребление слов с высокой токсичностью усилит агрессивность высказывания. В том числе в нашей модели это способно спровоцировать дискриминацию по религиозному признаку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e0736-dcc8-417b-8a31-2f261393379c",
   "metadata": {},
   "source": [
    "# Задание 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f33b539-8a56-4e6d-9f7d-143d2c9016f9",
   "metadata": {},
   "source": [
    "1)Заменить простую фильтрацию по коэффициенту токсичности на систему, учитывающую контекст (например, сарказм, цитирование, обсуждение самого слова). Это снизит количество ложных срабатываний и позволит отличать реальные оскорбления от нейтральных упоминаний.\n",
    "\n",
    "2)Сдвинуть фокус модели с общего поиска \"плохих слов\" на выявление системных угроз (например, язык, направленный против меньшинств, инвалидов, ЛГБТК+, женщин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d14de-11d5-4693-b130-e15ab6d77b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
