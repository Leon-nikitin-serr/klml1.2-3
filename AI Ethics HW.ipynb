{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "3faecc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb514c9e",
   "metadata": {},
   "source": [
    "#### Загрузка даных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "b02451e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the same results each time\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Load the training data\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "comments = data[\"comment_text\"]\n",
    "target = (data[\"target\"]>0.7).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a07953e",
   "metadata": {},
   "source": [
    "#### Исследование и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "74b5f1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 90902 entries, 0 to 90901\n",
      "Series name: comment_text\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "90902 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 710.3+ KB\n"
     ]
    }
   ],
   "source": [
    "comments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3fbd5",
   "metadata": {},
   "source": [
    "В датасете отсутсвуют пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "aed6b278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90902,)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Размерность датафрема comments\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "fe98d631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 90902 entries, 0 to 90901\n",
      "Series name: target\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "90902 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 710.3 KB\n"
     ]
    }
   ],
   "source": [
    "target.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f517c4f",
   "metadata": {},
   "source": [
    "В датасете отсутсвуют пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "fb913869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90902,)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7974b",
   "metadata": {},
   "source": [
    "### Задание 1 Теперь разделим наши данные на train и test. Пусть в тест у нас пойдет 30% данных. Для этого можете использовать библиотеку train_test_split из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "965f08d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочные признаки: 12294                                    Muslim terrorist.\n",
      "57506    It's ironic that these are the same groups tha...\n",
      "56118    Star Wars has a wow factor that Star Trek does...\n",
      "28624    The settlement is 100% appropriate.\\nEnding th...\n",
      "63482    Where did it say to cover your cough with your...\n",
      "                               ...                        \n",
      "6265     You fit perfectly in Clinton's libdem basket o...\n",
      "54886    I'll bet those independent contractors have no...\n",
      "76820    \"Lower tier\" people, especially the young, wer...\n",
      "860      The Devil made her do it and the man too becau...\n",
      "15795    A leak in an 8\" pipe, while obviously not a go...\n",
      "Name: comment_text, Length: 63631, dtype: object\n",
      "---------------------------------------\n",
      "Тренировочные метки: 12294    1\n",
      "57506    0\n",
      "56118    0\n",
      "28624    1\n",
      "63482    0\n",
      "        ..\n",
      "6265     1\n",
      "54886    0\n",
      "76820    0\n",
      "860      1\n",
      "15795    1\n",
      "Name: target, Length: 63631, dtype: int64\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    comments, target,           # данные\n",
    "    test_size=0.3,  # 30% — тестовая выборка, 70% — обучающая\n",
    "    random_state=42 # фиксируем случайность для повторяемости\n",
    ")\n",
    "\n",
    "# Выводим результат\n",
    "print(\"Тренировочные признаки:\", X_train)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Тренировочные метки:\", y_train)\n",
    "print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "66eb8eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Тестовые признаки: 80470    Not meaning to belittle your practical concern...\n",
      "28773    Did you mean to imply that the bears are dying...\n",
      "76685    As a 9-year dispatch veteran, let me break it ...\n",
      "12580    A your wimp is traveling across Canada instead...\n",
      "16111    Oh Dispatch, you right wing media elitist rag....\n",
      "                               ...                        \n",
      "27748    The problem with Trump's misogyny is that when...\n",
      "86400                                                 Why?\n",
      "40444    Bull crap!!! ask the Venezuelan's if their \\n\"...\n",
      "53979    Well if you read and understood my posts, you ...\n",
      "13216    you guys really still think that after 40 year...\n",
      "Name: comment_text, Length: 27271, dtype: object\n",
      "---------------------------------------\n",
      "Тестовые метки: 80470    0\n",
      "28773    1\n",
      "76685    0\n",
      "12580    1\n",
      "16111    1\n",
      "        ..\n",
      "27748    1\n",
      "86400    0\n",
      "40444    1\n",
      "53979    0\n",
      "13216    1\n",
      "Name: target, Length: 27271, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------\")\n",
    "print(\"Тестовые признаки:\", X_test)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Тестовые метки:\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ddf18",
   "metadata": {},
   "source": [
    "### Задание 2 Преобразуйте текст, который вы поделили на train и test, в числовой формат с помощью функции CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "a6216d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерноть датасета X_train_vec (63631, 200)\n",
      "Размерность датасета y_train (63631,)\n",
      "------------------------------------------------------\n",
      "Размерноть датасета X_train_vec (27271, 200)\n",
      "Размерность датасета y_train (27271,)\n"
     ]
    }
   ],
   "source": [
    "# Инициализация векторизатора\n",
    "vectorizer = CountVectorizer(max_features=200)\n",
    "\n",
    "# Преобразование датафрема X_train в новый датафрейм, в котором тексты заменены на вектора  \n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# Преобразование датафрема X_train в новый датафрейм, в котором тексты заменены на вектора  \n",
    "X_test_vec = vectorizer.fit_transform(X_test)\n",
    "\n",
    "## Сверяем размерность полученных датасетов \n",
    "print(f'Размерноть датасета X_train_vec', X_train_vec.shape)\n",
    "print(f'Размерность датасета y_train', y_train.shape)\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print(f'Размерноть датасета X_train_vec', X_test_vec.shape)\n",
    "print(f'Размерность датасета y_train', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8e96c",
   "metadata": {},
   "source": [
    "#### Задание 3 Теперь в качестве модели, которая будет классифицировать нам комментарии на токсичные и нетоксичные, возьмем логистическую регрессию. Импортируйте из библиотеки sklearn логистическую регрессию LogisticRegression с параметром max_iter=2000. Для оценки модели возьмите метрику accuracy и посчитайте ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "b3bd437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика Accuracy: 0.6065\n"
     ]
    }
   ],
   "source": [
    "# Инициализация и обучение модели логистической регрессии\n",
    "model = LogisticRegression(max_iter=2000, warm_start=True)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Предсказание на тестовой выборке\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Расчет accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Метрика Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79161c11",
   "metadata": {},
   "source": [
    "Получена метрика Accuracy - 0.6065"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0bb607",
   "metadata": {},
   "source": [
    "### Задание 4 Чтобы мы смогли протестировать разные комментарии, которые приходят в голову, пропишите ниже функцию, для которой на вход мы бы подавали наш комментарий, а на выход получали предсказание, насколько от 0 до 1 комментарий является токсичным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "fd695e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токсичное высказываение\n",
      "Нормальное высказываение\n"
     ]
    }
   ],
   "source": [
    "def check_toxic(text):\n",
    "\t\n",
    "\tif model.predict(vectorizer.transform([text])):\n",
    "\t\treturn print('Токсичное высказываение')\n",
    "\telse:\n",
    "\t\treturn print ('Нормальное высказываение')\n",
    "\n",
    "# Проверка\n",
    "\n",
    "test_text1 = \"Apples are stupid\"\n",
    "test_text2 = \"I love apples\"\n",
    "\n",
    "check_toxic(test_text1)\n",
    "check_toxic(test_text2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6430f47c",
   "metadata": {},
   "source": [
    "Подтверждаем, что молель корректно класифицирует высказывания "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f849d5",
   "metadata": {},
   "source": [
    "#### Задание 6 Если ваш алгоритм работает корректно, то комментарий «I love apples» должен быть определен как нетоксичный, а «Apples are stupid» — как токсичный. \n",
    "\n",
    "#### А теперь перейдем к пониманию того, как модель принимает решения: модель присваивает каждому из примерно 58 000 слов коэффициент, причем более высокие коэффициенты обозначают слова, которые модель считает более токсичными. \n",
    "\n",
    "#### Выведите десять слов, которые считаются наиболее токсичными, а также их коэффициенты.\n",
    "#### Hint: в этом вам поможет атрибут vectorizer.vocabulary_.keys() и classifier.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "4da59d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 токсичных слов:\n",
      "-------------------------\n",
      "idiot: 5.732400434893729\n",
      "idiots: 5.659027706355476\n",
      "such: 5.510022423357099\n",
      "ignorant: 3.7407246727464765\n",
      "who: 0.9464284920846445\n",
      "man: 0.5627805343047959\n",
      "they: 0.41925204665651905\n",
      "two: 0.3894660106423257\n",
      "left: 0.3184341495570787\n",
      "work: 0.2971392572980749\n"
     ]
    }
   ],
   "source": [
    "## формируем словарь и коэффиценты\n",
    "vocabls = vectorizer.vocabulary_\n",
    "coefs = model.coef_[0]\n",
    "\n",
    "index_to_word = {index: word for word, index in vocabls.items()}\n",
    "\n",
    "# Получаем 10 первых токсичных слов\n",
    "top_indices = np.argsort(coefs)[-10:][::-1]\n",
    "top_toxic_words = [(index_to_word[i], coefs[i]) for i in top_indices]\n",
    "\n",
    "# Вывод\n",
    "print(\"10 токсичных слов:\")\n",
    "print(\"-------------------------\")\n",
    "for word, weight in top_toxic_words:\n",
    "    print(f\"{word}: {weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119122f6",
   "metadata": {},
   "source": [
    "####  Задание 7 Взгляните на самые токсичные слова из задания 6. \n",
    "\n",
    "#### Вызывают ли у вас удивление какие-нибудь из них? \n",
    "\n",
    "Можно отметить, что большая часть слов из представленных в списке не явлюятся токсичными и не носят неготивной окрски\n",
    "\n",
    "#### Есть ли слова, которых, кажется, не должно быть в списке?\n",
    "\n",
    "Очевидно, что слова such (такой), who (кто), man (мужчина), they (они), ецщ (два), left (лево), work (работа)\n",
    "не могут быть отнесены к токсичным "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724ac64",
   "metadata": {},
   "source": [
    "### Задание 8 Давайте попробуем протестировать модель на ее предвзятость, например, к религии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba50d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормальное высказываение\n",
      "Нормальное высказываение\n",
      "Нормальное высказываение\n",
      "Нормальное высказываение\n"
     ]
    }
   ],
   "source": [
    "check_toxic(\"I have a christian friend\")\n",
    "check_toxic(\"I have a muslim friend\")\n",
    "check_toxic(\"I have a white friend\")\n",
    "check_toxic(\"I have a black friend\")\n",
    "\n",
    "## Все высказывания отнесены к нормльным высказываениям. Можно сделать вывод о том, что у модели нет предвзятости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8061add0",
   "metadata": {},
   "source": [
    "#### Задание 9 Немного теории: \n",
    "#### в этике ИИ принято писать такой алгоритм, который будет соответствовать 4 критериям этики:\n",
    "\n",
    "Предвзятость может приветси к тому, что даже обычное упоминение слов коэффицент токсичности которых выше, может повысить токсичность высказывания в целом. Может приводить к дескриминации по религиозному признаку.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b67b3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b23170f8",
   "metadata": {},
   "source": [
    "## Задание 10 Подумайте о том, как можно улучшить алгоритм, чтобы сделать его более этичным. Напишите 1–2 идеи.\n",
    "\n",
    "1. Возможно имело бы смысл проводить векторизацию текстов не на отдельные слова, а на словосочетания. \n",
    "Представляется, что такой подход повысит точность класификации текстов\n",
    "\n",
    "2. Для тренировки алгримтмов размечать датасеты не на 2 категории, а на 3 (токсичное, нейтральное, положительное)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
